\chapter*{Zusammenfassung}

\begin{otherlanguage}{german}

    Künstliche neuronale Netze sind inzwischen die populärste Art von Modell für
    viele Anwendungen im Maschinellen Lernen, z.B. Bildklassifikation,
    Segmentierung oder Video- und Audioanalyse sowie Zeitreihenvorhersage.  Mit
    immer zunehmenden Ressourcen und Fortschritten in verfügbarer Software
    steigt auch die Größe der Trainierbaren Modelle. Dennoch sind
    Trainingszeiten von Tagen und Wochen -- selbst auf potenter Hardware --
    nicht ungewöhnlich.

    Es gibt naheliegende Ursachen -- z.B. die Schwierigkeit, das Training zu
    parallelisieren aufgrund der eingesetzten Optimierungsalgorithmen -- jedoch
    möglicherweise auch weninger offensichtliche Verluste in der Art und Weise,
    wie Modelle normalerweise trainiert werden.

    Während der praktische Erfolg tiefer neuronaler Netze rapide war, konnte die
    theoretische Erschließung nicht Schritt halten, und viele fortschrittliche
    Ideen sind mehr von Intuition und Experimenten gestützt als von rigorosen
    Formalismen.  Für die meisten erfolgreichen Ideen haben wir folglich kein
    klares Verständnis dafür, warum sie in der Praxis gut funktionieren.

    Diese Kluft zwischen Praxis und Theorie ist auch ursächlich dafür, dass
    Deep-Learning-Applikationen mehr als Kunst denn als Wissenschaft gilt.
    Anders als in der traditionellen Softwareentwicklung, die auf Jahrzenten der
    Forschung in Ingenieurswissenschaften, Mathematik und theoretischer
    Informatik basiert, gibt es im maschinellen Lernen oft keinen definitiven Ansatz, um ein
    konkretes Problem zu lösen. Des Weiteren sind die verfügbaren
    Debugging-Wekrzeuge in jeder Schicht der Softwareentwicklung denen des Deep
    Learning bei weitem überlegen. Einfache Fragen wie ``Lernt das Modell das, was ich möchte?''
    sind bislang nicht zu beantworten. Wir können hier also eine Notwendigkeit
    für mehr nützliche Tools für Anwender konstatieren.

    Der Standardweg, eine gute Parameterwahl für das Modell zu treffen ist Trial-and-Error
    oder etwas intelligentere Variationen. Der Rechenaufwand für das Training großer Modelle
    verhindert schnelles Experimentieren und schlägt sich häufig auch in finanziellen Kosten nieder.
    Frühzeitig Sackgassen zu identifizieren oder Zeitpunkte, an denen man bestimmte Parameter ändern sollte,
    könnten daher große Ersparnisse bedeuten.

    Diese Arbeit stellt zum Einen eine Softwarebibliothek vor, die im Debugging
    von Deep-Learning-Anwendungen hilft und das Experimentieren erleichtert. Zum
    Anderen wird dieses Werkzeug benutzt, um experimentell festzustellen, ob aus
    dem Trainingsprozess Signale extrahiert werden können, die Aufschluss über
    die Wahl von Parametern geben, während das Training läuft.

\end{otherlanguage}
