\chapter*{Abstract}

Artificial neural networks have become the prevalent model class for many
machine learning tasks, including image classification, segmentation, video and
audio analysis, or time series prediction. With ever increasing computational
resources and advances in programming infrastructure, the size of model we can
train also increases. Nevertheless, it is not uncommon for training to take days
or weeks, even on potent hardware. While there are many obvious causes -- e.g.
inherent difficulty to parallelize training with the most successful algorithms
-- there may still be inefficiencies in the framework we typically use for
training neural networks. While the success of deep learning models has been
rapid, the theoretical justification for most game-changing ideas as well as the
general principles of deep learning, has not kept pace (for more information,
see Sanjeev Arora's talk at ICML 2018
\footnote{\href{https://www.youtube.com/watch?v=rcR6P5O8CpU}{Toward Theoretical
Understanding of Deep Learning}}). This means that for many successful
techniques, we have no clear understanding why they work so well in practice.


This explanatory gap is also a reason why developing deep learning applications is considered more of an art than a
science. In contrast to traditional programming, which builds on decades of reasearch and development in electrical
engineering, logic, mathematics and theoretical computer science, there's rarely one definitive way to solve a certain
problem in deep learning. Additionally, the debugging tools available to every programmer on every level of abstraction
far exceed what we currently have for differentiable programming. Simple questions like ``Does my model learn what I want
it to learn?'' are not answerable at this point.  We can thus identify a need to supply more useful tooling for deep
learning practitioners.  A standard approch to choosing a parametrization remains trial-and-error, or only slighty more
sophisticated ways to run and test.  The computational cost of training large models prohibits quick experimentation and
often translates into monetary costs as well. Identifying dead ends early or points in training  when to tweak certain
parameters could thus provide large savings in time and money, besides enabling a more thorough understanding of what is
going on.

This thesis addresses the above in two ways: A software library aiding in deep learning debugging and experimentation is
designed and implemented. The same library is then used to investigate experimentally, whether heretofore unknown
signals can be extracted from the training process in order to validate parameter choices while training is running.
