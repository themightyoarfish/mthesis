\chapter*{Abstract}

Artificial neural networks have become the prevalent model class for many
machine learning tasks, including image classification, segmentation, video and
audio analysis, or time series prediction. With ever increasing computational
resources and advances in programming infrastructure, the size of model we can
train also increases. Nevertheless, it is not uncommon for training to take days
or weeks, even on potent hardware. While there are many obvious causes---e.g.
inherent difficulty to parallelize training with the most successful algorithms
-- there may still be inefficiencies due to our incomplete knowledge of training
dynamics which is compensated for by expensive parameter search.

The pragmatic approach to opening the black box of deep learning is
through experimentation and observation. Experiments are being performed to
obtain insights into the training process, and said insights can then be used to
guide the training.  The speed and ease at which experiments can be performed is
tied to the availability of tooling for the experimenter.

In this thesis, a software library is presented which facilitates both
experimenting on metrics which can guide and ultimately accelerate the learning
process and monitoring these metrics in practice. The library is then used to
investigate a selection of metrics in order to find out if heretofore unknown
signals can be extracted for informing parameter choices during training. Also,
the library is used for validating known or claimed results, highlighting its
usefulness for deep learning research.
