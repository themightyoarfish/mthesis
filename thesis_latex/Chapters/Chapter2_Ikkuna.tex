\hypertarget{ikkuna}{%
\chapter{Ikkuna}\label{ikkuna}}

Ikkuna is the Python library developed for this thesis. It targets
Python 3.6 and was designed with the following goals in mind:

\begin{enumerate}
    \item
        Ease of use. Minimal configuration, maximum rewards.
    \item
        Flexible and all-encompassing API enabling creating arbitrary metrics
        which act on training artifacts
    \item
        Metrics shall be agnostic of model code.
    \item
        Plugin architecture so metrics written once can be used for any kind
        of model
    \item
        Framework agnosticism. Ideally, the library would support every deep
        learning framework through an extensible abstraction layer.
\end{enumerate}

What it provides over the aforementioned tools is that it enables
working at a higher level of abstraction, liberating the developer from
having to repeat herself, exchanging visualizations and metrics and
reduce the friction between development and debugging. This chapters gives a
high-level overview of the library components and elaborates on the design
decisions made during the creation. Throughout the chapters, UML class and
package diagrams will serve as a mental map for the reader. For brevity, not all
parts of the library are diagrammed down to the same level of detail.

\hypertarget{design-principles}{%
\section{Design Principles}\label{design-principles}}

Of the aforementioned goals, all except one have been accomplished. The
objective of making the library agnostic to the deep learning framework
being used (TensorFlow, PyTorch, PyCaffe, Chainer, etc.) has been
neglected for practical reasons. Enabling this kind of support is beyond
the scope of this thesis and only requires the implementation of a
software layer which offers framework-agnostic access to network
modules, activations, gradients and all the other necessary information.
While this is certainly possible and useful, the PyTorch framework has
been chosen for this work to create a proof of the concept. The choice is
motivated in \cref{sec:dl-frameworks}.

The overarching architecture of this software must lend itself to this
agnosticity goal, however. As such, a very loose coupling between model code,
metric computation and visualizations is desired. Not only will this aid in
extending the library to different deep learning frameworks, but it is also a
prerequisite for allowing for modular, self-contained visualizations or metrics
which can be installed and used separately and independently of specific model
code. The Publisher-Subscriber design pattern has been chosen for these reasons
(\cref{sec:pubsub}).

\hypertarget{sec:dl-frameworks}{%
\section{Deep Learning frameworks}\label{sec:dl-frameworks}}

The currently available deep learning libraries can be located on a spectrum
between define-by-run and define-and-run.  The first extreme would be a
framework such as PyTorch \citep{paszke2017automatic} or Chainer
\citep{tokui2015chainer} , where there exist no two distinct execution phases --
just like in an ordinary matrix library like NumPy, each statement immediately
returns or operates on an actual value. By contrast, graph-based frameworks like
TensorFlow\footnote{Since version 1.4, TensorFlow gravitates toward
    define-by-run through the introduction of \emph{eager execution}, which
becomes the default mode in version 2.0. Graph-based execution is still
available, but not the default any longer.} require specifying the model graph
in a domain-specific language (TensorFlow has Python, Java and C++ APIs, Caffe
uses Prototxt files), compile it to a different representation and the the model
is run and trained in a second phase. While this enables graph-based
optimizations, the main downsides are that

\begin{itemize}
    \item
        control flow cannot use the host language features, but must be done
        with the API used for defining models. Instead of
        \begin{lstlisting}[language=Python, label=lst:whilepy-pt, gobble=8]
        counter = torch.tensor(0)
        # repeated matrix multiplication
        while counter < tensor:
            counter += 1
            h = torch.matmul(W, h) + b
        \end{lstlisting}

        one must use a construction like this
        \begin{lstlisting}[language=Python, label=lst:whilepy-tf, gobble=8]
        counter = tf.constant(0)
        while_condition = lambda counter: tf.less(counter, tensor)
        # loop body
        def body(counter):
            h = tf.add(tf.matmul(W, h), b)
            # increment counter
            return [tf.add(counter, 1)]

        # do the actual loop
        r = tf.while_loop(while_condition, body, [counter])
        \end{lstlisting}
    \item
        As a corrolary, the barrier of entry is higher, since a beginner cannot rely on the
        language feature she knows but must learn how to express many concepts
        without the host language.
    \item
        halting execution at aribtrary points in the training is not possible,
        since the actual training is not happening in the host language, but
        is more often handed off to lower-level implementations in its
        entirety.
\end{itemize}

This makes conditional processing and debugging much less ergonomic.

All frameworks have in common that they build a graph representation of
the model, wether implicitly or explicitly. Nodes in the graph are
operations while edges are data flowing between operations. This allows
naturally parallelizing independent computations. To compute gradients,
the graph can be traversed backwards from the output node by applying
the chain rule of differentiation. Define-and-run frameworks like
TensorFlow create the graph explicitly; the user uses the API to do
exactly this. The graph -- once compiled -- is fixed for the entire
training process. PyTorch on the other hand implicitly records all
operations and also overloads operators for this purpose. The graph is
thus recreated for each propagation through the network. This precludes
some optimizations, but makes dynamically changing networks easily
achievable.

For this work, the PyTorch framework has been chosen, due to the fact
that it is growing quickly in popularity (see \cref{fig:popularity}) and
relatively new, so the ecosystem is not fully developed and some
utilities available for e.g.~TensorFlow are not available for PyTorch.
Because of this, an introspection framework for training momnitoring is
judged to present the best value proposition for PyTorch users.

\begin{figure}
    \hypertarget{fig:popularity}{%
        \centering
        \includegraphics[max width=\textwidth]{gfx/diagrams/framework_popularity/popularity.pdf}
        \caption[Changes in popularity of different deep learning libraries in
        research]{Changes in popularity of different deep learning libraries in
            research. Data was collected by keyword search over ICLR submissions
            (\href{http://search.iclr2019.smerity.com/search/}{http://search.iclr2019.smerity.com/search};
        analogously for 2018)}\label{fig:popularity}
    }
\end{figure}

\hypertarget{sec:pubsub}{%
\section{Publisher-Subscriber}\label{sec:pubsub}}

The Publisher-Subscriber pattern (for a detailed overview see
\cite{eugster2003}) is a pattern for distributed computation in which publishers
publish messages either directly to any subscribers which have registered
interest in them, or to a central authority orchestrating the exchange. Messages
are generally associated with one or more topics and subscribers register
interest in receiving messages on one or more topics.

The compontens are very loosely coupled; the subscribers need not even
be aware of the publishers at all, and the publishers' only interaction
with their subscribers is relaying messages through a uniform interface
or through an optional server. A graphical schema of one possible
incarnation of this pattern is shown in \cref{fig:pubsub}.

\begin{figure}
    \hypertarget{fig:pubsub}{%
        \centering
        \includegraphics[max width=\textwidth]{gfx/diagrams/architecture_diagrams/pubsub.pdf}
        \caption{One possible implementation of the Publisher-Subscriber pattern.}\label{fig:pubsub}
    }
\end{figure}

This project is not distributed, but can benefit from the loose coupling
in another way: Subscribers can be defined in terms of the kind of
messages they need to compute their metric, without knowing anything
about where the messages are coming from. Concretely, as long as the
appropriate data is emitted from the training process, subscribers can
work without modifications with any possible model.

Since real-world neural networks are trained on the GPU, and
communication between host and GPU memory is expensive, making this
library truly distributed is not an objective. However, the design will
simplify asynchronous computation of metrics in the future. The Python
language does not support true multithreading\footnote{The
    \texttt{multiprocessing} module allows for truly
    asynchronous computation and communication, but the
    inter-process-communication is more expensive than memory shared
between threads.}, but since the expensive part of the work is running
on the GPU while the host code is waiting, metric computation could
happen asynchronously on the GPU as well while the expensive forward or
backward passes through the network are running. This is not currently
implemented but can be added later, if more computationally demanding
metrics are to be explored.

In the context of neural network training, there is only one source of
information and hence only one publisher. Therefore, the message server
is folded into the singular publisher which extracts data from the
training model and sends messages to any interested subscribers.

\hypertarget{overview-of-the-library}{%
\section{Overview of the library}\label{overview-of-the-library}}

The software is structured into several packages. The root package is
\texttt{ikkuna} which encapsulates all core
functionality. All other packages and modules contain utilites
implemented for this work specifically, but will generally not be
relevant to other users. A survey of these tools will be given in
\cref{sec:other-tools}.

The root package diagram is shown in \cref{fig:pack-diag-ikkuna}

\begin{figure}
    \hypertarget{fig:pack-diag-ikkuna}{%
        \centering
        \includegraphics[max width=.7\textwidth]{gfx/diagrams/class_diagrams/ikkuna_package_diagram.pdf}
        \caption{\texttt{ikkuna} package diagram}\label{fig:pack-diag-ikkuna}
    }
\end{figure}

The \texttt{models} (see \cref{sec:pack-models})
subpackage contains a few exemplary neural network definitions which are
wired up with the library and can thus be used to showcase the library's
functionality. The \texttt{utils} (see
\cref{sec:pack-utils}) subpackage contains miscellaneous utility classes
and functions used throughout the core library. Lastly, the
\texttt{visulization} subpackage
(\cref{sec:pack-visualization}) contains the plotting functionality to
actually show the metrics computed during the training process.

The most important bits of the software live in the
\texttt{export} subpackage (\cref{sec:pack-export}). It
implements the Publisher-Subscriber pattern. Extracting data from the
training process, defining subscriber functionality and messages used
for communication is done here.

\hypertarget{sec:pack-export}{%
\subsection{The \texttt{export} subpackage}\label{sec:pack-export}}

The \texttt{export} subpackage contains the core part
of the library, i.e.~it provides the classes that handle discovering the
structure of the neural network model, attaching the appropriate
callbacks and intercepting method calls on the model so the library is
informed about everything entering and exiting the model and its
individual layers. It also contains the definition for the subscriber
API, i.e.~the messages that subscribers can receive, synchronisation
facilities when multiple topics are needed by a subscriber, as well as
the subscriber class interface. The package diagram is displayed in
\cref{fig:pack-diag-export}.

The package comprises three subpackages or modules listed in
\cref{tbl:ikkuna.export}

\begin{table}
    \caption{\texttt{ikkuna.export} functionalities}
    \label{tbl:ikkuna.export}
    \begin{tabularx}{\textwidth}{lX}
        \toprule
        Name                & Function\tabularnewline
        \midrule
        \texttt{export}     & Publish data from an arbitrary model and send messages to registered subscribers\tabularnewline
        \texttt{messages}   & Define message interface; i.e.~what topics exist and which information a message must contain\tabularnewline
        \texttt{subscriber} & Define the base class for metric subscribers\tabularnewline
        \bottomrule
    \end{tabularx}
\end{table}

\subsubsection*{The \texttt{ikkuna.export} subpackage}

\begin{figure}
    \hypertarget{fig:pack-diag-export}{%
        \centering
        \includegraphics[max width=.7\textwidth]{gfx/diagrams/class_diagrams/export_package_diagram.pdf}
        \caption{\texttt{ikkuna.export} package diagram}\label{fig:pack-diag-export}
    }
\end{figure}

In in slight deviation from the Publisher-Subscriber framework as displayed in
\cref{fig:pubsub}, the \texttt{export.Exporter} class
(\cref{fig:class-diag-exporter}) is the sole publisher of data. There is only one
source of data during training, so it is unnecessary to accomodate multiple
subscribers. The \texttt{Exporter} is informed of the model with its methods
\lstinline{set_model()} and \lstinline{set_loss()}, the latter of which is only
necessary if metrics which rely on training labels should be displayed.  It can
accept a filter list of classes which are to be included when discovering the
modules in the model. For instance, it could be desirable to only observe layers
which have weights and biases associated with them, not e.g.~normalisation or
reshaping layers. The \texttt{Exporter} then traverses the model (which is
really just a tree structure of modules) and adds to each a callback invoked
when input enters the layer -- in order to retrieve activations -- and when
gradients are computed for the layer outputs. The callbacks also use cached
weights -- if present -- in order to publish updates to the weights.
Furthermore, it replaces a few of the model's methods with closure wrappers so
it can

\begin{itemize}
    \item
        be notified when the model is set to training or testing mode (this
        switch disables or enables layers which only make sense during one of
        the phases\footnote{There are two built-in layers this applies to. One
            is the batch normalisation layer. It normalises the output of the
            previous layer with the mean and variance over the entire batch of
            data -- optionally with running means and variances over the
            previousprevious training steps. The variance is not defined for
            single data point enters the layer, as could be the case during
            inference/testing time. The second case is the dropout layer, which
            randomly zeroes out a percentage of the previous layer's
            activations. This is used during training to prevent subsequent
            units from becoming correlated with a fixed set of units in the
            previous layer, instead of picking up patterns invariant of where in
            the input they occur. During inference time, this is turned off to
            make full use of the trained
        layers.})
    \item
        increase its own step counter automatically when a new batch is seen
    \item
        add a parameter to the model's \lstinline{forward()} method -- called by
        the runtime when data is propagated through the model -- which can be
        used be subscribers to temporarily turn off training mode and have it
        revert automatically. This is useful for subscribers which need to
        evaluate the model (i.e.~feed data through it), but do not want to
        generate new messages for this occasion.
    \item
        intercept labels passed to the loss function during training and
        publish them as messages so the user need not concern himself with
        this task
    \item
        intercept the final output of the network. This could be realised
        alternatively by identifying the last module in the network.
\end{itemize}

At every time step (training batch), the \texttt{Exporter} publishes the
following information:

\begin{itemize}
    \item
        gradients for each module
    \item
        activations for each module
    \item
        weights and biases for each module that has these properties
        (e.g.~convolutional or fully-connected layers)
    \item
        updates to the weights and biases from the last step to the current
        one, provided the module has these properties
    \item
        Training labels used for the parameter updates. This requires that the
        \texttt{Exporter} be informed of the loss function object with
        \lstinline{set_loss()}.
    \item
        The batch of input data passed to the network at the current training step
    \item
        The final output of the network for the current batch of training data.
        This is simply the tensor of activations from the last layer and is thus
        technically duplicated since activations are published anyway. The
        reason is that some subscribers may only be interested in the network
        predictions and it is unnecesary to determine automatically the last
        layer in the network as the loss function has automatic access to
        the activations and must be tracked anyway for the training labels
\end{itemize}

Further messages are published only at certain points in the training process

\begin{itemize}
    \item
        When a batch starts or ends, a message with the current batch index is published
    \item
        When an epoch starts or ends, a message with the current batch index is
        published. This requires the \texttt{Exporter} be notified with
        \lstinline{epoch_finished()} by the user, since it is impossible to
        determine when an epoch is over from inside the model.
\end{itemize}

\subsubsection*{The \texttt{ikkuna.export.messages} submodule}

This submodule contains definitions of all permissible messages kinds, message
classes and a collection class for message objects. An overview of the classes
defined in this module is shown in \cref{fig:messages_class_diag}.

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{{gfx/diagrams/class_diagrams/ikkuna.export.messages}.pdf}
    \caption{Classes in the \texttt{ikkuna.export.messages} submodule}
    \label{fig:messages_class_diag}
\end{figure}

Messages are of one of two types: They are either directly tied to a layer in
the network and are thus published for each layer, or they contain information
for the current training step. In that case, they appear only once per training
step, not once per layer. The meta-messages can carry tensor data (e.g.~input
data or labels), but need not to (e.g.~notifications about a starting or ending
epoch). All message kinds are summarised in \cref{tbl:messages}

\begin{table}
    \centering
    \caption{Subscribable message kinds}
    \label{tbl:messages}
    \begin{tabularx}{\textwidth}{llX}
        \toprule
        \rowcolor{verylightblue}\multicolumn{3}{c}{Meta topics} \tabularnewline
        \midrule
        Identifier                     & Frequency                & Description \tabularnewline
        \midrule
        {\lstinline!batch_started!}    & Once every batch         & \tabularnewline
        {\lstinline!batch_finished!}   & \ditto                   & \tabularnewline
        {\lstinline!epoch_started!}    & Once every epoch         & \tabularnewline
        {\lstinline!epoch_finished!}   & \ditto                   & \tabularnewline
        {\lstinline!input_data!}       & Once every batch         & \tabularnewline
        {\lstinline!input_labels!}     & \ditto                   & \tabularnewline
        {\lstinline!network_output!}   & \ditto                   & Activations of the last layer \tabularnewline
        \bottomrule
        \rowcolor{verylightblue}\multicolumn{3}{c}{Data topics} \tabularnewline
        \midrule
        Identifier                     & Frequency                & Description \tabularnewline
        \midrule
        {\lstinline!weights!}          & Once per layer per batch & Gradients of loss function w.r.t. layer weight matrix \tabularnewline
        {\lstinline!weight_gradients!} & \ditto                   & \tabularnewline
        {\lstinline!weight_updates!}   & \ditto                   & \tabularnewline
        {\lstinline!biases!}           & \ditto                   & Gradients of loss function w.r.t. layer bias matrix \tabularnewline
        {\lstinline!bias_gradients!}   & \ditto                   & \tabularnewline
        {\lstinline!bias_updates!}     & \ditto                   & \tabularnewline
        {\lstinline!activations!}      & \ditto                   & \tabularnewline
        {\lstinline!layer_gradients!}  & \ditto                   & Gradients of loss function w.r.t. layer output \tabularnewline
        \bottomrule
    \end{tabularx}
\end{table}

\begin{figure}
    \hypertarget{fig:class-diag-exporter}{%
        \centering
        \includegraphics[max width=.8\textwidth]{gfx/diagrams/class_diagrams/{ikkuna.export.Exporter}.pdf}
        \caption{\texttt{ikkuna.export.Exporter} class diagram}\label{fig:class-diag-exporter}
    }
\end{figure}

\subsubsection*{The \texttt{ikkuna.export.subscriber} subpackage}

The third subpackage contained in the \texttt{ikkuna.export} package defines the
subscriber part of the Publisher-Subscriber pattern. The diagram of the defined
classes is shown in \cref{fig:class-diag-subscriber}. The \texttt{Subscriber}
base class is rudimentary and mandates only the implementation of the metric
computation by subclasses. In the simplest case, a subscribers is interested in
only one topic and therefore is coupled to a simple \texttt{Subscription}
object, which handles bookkeeping tasks such as subsampling the messaage stream,
routing only relevant messages to the subscriber and counting the received messages.

More generally however, a subscriber may want to receive several pieces of
information for each layer in each time steps (i.e.~for computing the ratio
between weight updates and weights). Since the order of messages is not
guaranteed, the desired messages are unlikely to occur one after the other;
instead the topics must be synchronised. A \texttt{SynchronizedSubscription}
buffers messages of the relevant topics until all requested kinds have been
received for the current training step, before releasing them to the subscriber.
A subscriber can thus receive a single message or a bundle of messages.

The library comes with a few subscribers already installed (they are themselves
plugins, see \cref{plugin-infrastructure}). Details are given in
\cref{tbl:subscribers}

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{gfx/diagrams/class_diagrams/{ikkuna.export.subscriber}.pdf}
    \caption{Classes defined in \texttt{ikkuna.export.subscriber}}
    \label{fig:class-diag-subscriber}
\end{figure}

\begin{table}
    \centering
    \caption{Pre-packaged subscriber subclasses}
    \label{tbl:subscribers}
    \begin{tabularx}{\textwidth}{lX}
        \toprule
        Name                             & Functionality                                                                                                                                                         \tabularnewline
        \midrule
        \texttt{MeanSubscriber}          & Computes the mean $\mu = \frac{1}{n}\sum_{i=1}^n w_i$ of a tensor                                                                                                     \tabularnewline
        \texttt{VarianceSubscriber}      & Computes the variance $\sum_{i=1}^n (w_i - \mu)^2$ for a tensor                                                                                                       \tabularnewline
        \texttt{SumSubscriber}           & Computes the sum $\sum_{i=1}^n w_i$ of a tensor                                                                                                                       \tabularnewline
        \texttt{NormSubscriber}          & Computes the $p$-Norm $\sqrt[p]{\sum_{i=1}^n w_i^p}$                                                                                                                  \tabularnewline
        \texttt{RatioSubscriber}         & Computes the average ratio $\frac{1}{n}\sum_{i=1}^n \frac{a_i}{b_i}$ of two tensors, disregarding NaN values                                                          \tabularnewline
        \texttt{HistogramSubscriber}     & Computes the histogram of a given tensor. This is computationally heavy.                                                                                              \tabularnewline
        \texttt{SpectralNormSubscriber}  & Computes the spectral norm (largest signular value) $\max_{\mathbf{h}:\mathbf{h}\neq 0} \frac{\left||A\mathbf{h}\right||_2}{\left||\mathbf{h}\right||_2}$ of a tensor \tabularnewline
        \texttt{TestAccuracySubscriber}  & Computes the ratio of correctly classified examples to total examples over the test set                                                                               \tabularnewline
        \texttt{TrainAccuracySubscriber} & Computes the ratio of correctly classified examples to total examples over current batch of training data                                                             \tabularnewline
        \bottomrule
    \end{tabularx}
\end{table}

\hypertarget{sec:pack-models}{%
\subsection{The \texttt{models} subpackage}\label{sec:pack-models}}

\begin{figure}
    \hypertarget{fig:pack-diag-models}{%
        \centering
        \includegraphics[max width=.7\textwidth]{gfx/diagrams/class_diagrams/models_package_diagram.pdf}
        \caption{\texttt{ikkuna.models} package diagram}\label{fig:pack-diag-models}
    }
\end{figure}

This package shown in \cref{fig:pack-diag-models} contains model
definitions for demonstration purposes and for experimentation. Three
architectures are currently implemented:

\begin{enumerate}
    \item
        A minified version of AlexNet, since the original architecture
        requires larger images \citep{krizhevsky2012imagenet}. The
        code is adapted from the PyTorch implementation.
    \item
        DenseNet \citep{huang2017densely}. The implementation is basically the
        one from \citep{pleiss2017memory}\footnote{At the time of writing, the
            implementation is available here:
            \url{https://github.com/gpleiss/efficient_densenet_pytorch/blob/master/models/densenet.py}.
            The licensing is unclear as the author references the original
            BSD-licensed implementation at
            \url{https://github.com/pytorch/vision/blob/master/torchvision/models/densenet.py}
            which was licensed by PyTorch core contributor Soumith Chintala.
            However, the code does not reproduce the BSD license text and can
            thus only be inspired by the original but cannot contain any of the
        code verbatim. It would require careful examination in order to
    determine whether this is the case.} with minor modifications
    \item
        ResNet \citep{he2016deep}. This implementation comes from
        GitHub user liukang\footnote{The implementation is MIT-licensed.
        \url{https://github.com/kuangliu/pytorch-cifar/blob/master/models/resnet.py}}
        and can handle CIFAR10-sized images of 32 pixels per side, as opposed
        to most implementaions that are geared towards ImageNet examples which
        are much larger.
\end{enumerate}

All models are modified such that their training can be supervised by
the library.

\hypertarget{sec:pack-utils}{%
\subsection{The \texttt{utils} subpackage}\label{sec:pack-utils}}

As shown in \cref{fig:pack-diag-utils}, this package defines classes for
traversing a model into a hierarchical tree of layers (called \emph{modules} in
PyTorch lingo), structures for adding information to PyTorch's \texttt{Module}
class, and a set of miscellaneous functions for

\begin{enumerate}
    \item
        Seeding random number generators to make experiments reproducible (see
        \cref{ch:appendixB})
    \item
        Creating instances of weight optimizers by named
    \item
        Initialize the weights of any model
    \item
        Loading datasets
\end{enumerate}

\begin{figure}
    \hypertarget{fig:pack-diag-utils}{%
        \centering
        \includegraphics[max width=.7\textwidth]{gfx/diagrams/class_diagrams/utils_package_diagram.pdf}
        \caption{\texttt{ikkuna.utils} package diagram}\label{fig:pack-diag-utils}
    }
\end{figure}

Additionally, it contains the \texttt{numba} module
which is inteded to allow interoperability with the Numba
library\footnote{\url{https://numba.pydata.org/}. Numba is a library for
    transforming high-level Python code into performant compiled code and
    for allowing to use the CUDA library from Python with Python arrays.
    This enables performance improvements for numeric calculations, but
    there is only a limited set of higher-level functions implemented on
GPU arrays.}. While currently not used due to the incomplete nature of
the Numba GPU array interface, it could enable leveraging Numba in the
future without transferring data to the CPU. The core function was later
obsoleted by an addition to the PyTorch library\footnote{The main contribution
of the submodule was to make PyTorch tensors accesible to Numba by
monkey-patching the \lstinline{__cuda_array_interface__} property. This has since
been added via pull request \#11984 to the PyTorch repository.}.

\hypertarget{sec:pack-visualization}{%
\subsection{The \texttt{visualization} subpackage}\label{sec:pack-visualization}}

This package contains only a single module:
\texttt{backend}. It defines the classes shown in
\cref{fig:class-diag-backend}. The module serves as an abstraction over
plotting libraries so that metrics need not concern themselves with how
to actually show the data.

A given metric will compute its value and dispatch it to its
visualization backend, which can currently accept scalar and histogram
data. The metric class itself need not care about how it is going to be
displayed.

\begin{figure}
    \hypertarget{fig:class-diag-backend}{%
        \centering
        \includegraphics[max width=\textwidth]{gfx/diagrams/class_diagrams/{ikkuna.visualization}.pdf}
        \caption{Class diagram for classes in \texttt{ikkuna.visualization}}\label{fig:class-diag-backend}
    }
\end{figure}

For running the library locally, a \texttt{matplotlib}-based backend has been
implemented.  Plotting routines from this library open a window directly on the
system executing the software. In practice however, deep learning code will be
executed remotely on a server with adequate compute capability and the
programmer connected via SSH. While it is possible to have remote windows show
up locally on Linux-based systems by use of X11-Forwarding, this is generally
slow and not useful for interactivity. An example is shown in
\cref{fig:example_mpl} To remedy this issue, a plotting backend for TensorBoard
(see \cref{sec:existing-apps}) is also provided. The plotting data is generated
and processed on the remote system, but served over the web so it can be viewed
and interacted with locally (provided the network is configured so that the
server responds to HTTP requests). An example is shown in \cref{fig:example_tb}.

\begin{figure}
    \hypertarget{fig:example_mpl}{%
        \centering
        \includegraphics[max width=\textwidth]{gfx/diagrams/software_screens/example_mpl.png}
        \caption{Exemplary view of a matplotlib figure forwarded over SSH}\label{fig:example_mpl}
    }
\end{figure}

\begin{figure}
    \hypertarget{fig:example_tb}{%
        \centering
        \includegraphics[width=\textwidth]{gfx/diagrams/software_screens/example_tb.png}
        \caption{Exemplary view of a TensorBoard session}\label{fig:example_tb}
    }
\end{figure}

\hypertarget{sec:other-tools}{%
\subsection{Miscellaneous tools}\label{sec:other-tools}}

There are a few modules which simplify development with the library but are not
part of the distribution obtained from PyPi or by running the setup script.

The \texttt{train} package defines a \texttt{Trainer} class which encapsulates
all the logic and parameters needed to train a neural network on one of the
datasets provided with PyTorch. The class's capabilities include the following

\begin{itemize}
    \item
        Look up model and dataset by name
    \item
        Bundle all hyperparameters
    \item
        hook the \texttt{Exporter} into the model for
        publishing data
    \item
        configure the optimisation algorithm to use for training
    \item
        train the model for one batch
\end{itemize}

The \texttt{Trainer} class is used in the main script (\texttt{main.py}), which
serves as a command line interface to the library while developing. When trying
out the library, it can also be used as an initial starting point.

\begin{table}
    \caption{Named arguments to \texttt{main.py}}
    \begin{tabularx}{\linewidth}{lX}
        \toprule
        Parameter                                   & Explanation\tabularnewline
        \midrule
        \lstinline{-m}, \lstinline{--model}         & Model class to train\tabularnewline
        \lstinline{-d}, \lstinline{--dataset}       & Dataset to train on. Possible choices: \lstinline{MNIST}, \lstinline{FashionMNIST}, \lstinline{CIFAR10}, \lstinline{CIFAR100}\tabularnewline
        \lstinline{-b}, \lstinline{--batch-size}    & Default: 128\tabularnewline
        \lstinline{-e}, \lstinline{--epochs}        & Default: 10\tabularnewline
        \lstinline{-o}, \lstinline{--optimizer}     & Optimizer to use. Default: \lstinline{Adam}\tabularnewline
        \lstinline{-a}, \lstinline{--ratio-average} & Number of ratios to average for stability (currently unused). Default: 10\tabularnewline
        \lstinline{-s}, \lstinline{--subsample}     & Number of batches to ignore between updates. Default: \lstinline{1}\tabularnewline
        \lstinline{-v}, \lstinline{--visualisation} & Visualisation backend to use. Possible choices: \lstinline{tb}, \lstinline{mpl}. Default: \lstinline{tb}\tabularnewline
        \lstinline{-V}, \lstinline{--verbose}       & Print training progress. Default: \lstinline{False}\tabularnewline
        \lstinline{--spectral-norm}                 & Use spectral norm subscriber on weights. Default: \lstinline{False}\tabularnewline
        \lstinline{--histogram}                     & Use histogram subscriber(s)\tabularnewline
        \lstinline{--ratio}                         & Use ratio subscriber(s)\tabularnewline
        \lstinline{--test-accuracy}                 & Use test set accuracy subscriber. Default: \lstinline{False}\tabularnewline
        \lstinline{--train-accuracy}                & Use train accuracy subscriber. Default: \lstinline{False}\tabularnewline
        \lstinline{--depth}                         & Depth to which to add modules.  Default: \lstinline{-1}\tabularnewline
        \bottomrule
    \end{tabularx}
\end{table}

The library can be installed to the local Python environment by use of the
provided setuptools script (\texttt{setup.py}). It can also be downloaded from
the \href{https://pypi.org/}{Python Package Index} by use of the package manager
\texttt{pip}:
\begin{lstlisting}[language=Python]
pip install ikkuna
\end{lstlisting}

\hypertarget{plugin-infrastructure}{%
\subsection{Plugin Infrastructure}\label{plugin-infrastructure}}

Among the main selling points of this library is the provision to add new
metrics as plugins and reuse them system-wide for all architectures. Plugins in
Python projects can be enabled through appropriate use of the
\texttt{setuptools} library. During the setup process for installing the
library, entry points are defined by the library which can be used by plugins to
announce themselves. Ikkuna provides the
\lstinline[language=Python,breaklines=false]{'ikkuna.export.subscriber'} entry
point. For registering a plugin, the author must simply use that entry point to
make a plugin available either through the package it is defined in, or through
the \lstinline{ikkune.export.subscriber} namespace. For illustration,
\cref{lst:plugin} shows how to setup a \texttt{setup.py} setuptools file. The
plugin can be installed like any other Python package with
\begin{lstlisting}[language=Python]
python setup.py install
\end{lstlisting}
which will install all required dependencies inside the current environment. The
PyTorch library must be installed manually since the binaray distribution is too
old at the time of writing. Detailed instructions can be found in the user guide
which is part of the documentation.

\begin{lstlisting}[label=lst:plugin, language=Python, caption=Sample setup script for subscriber plugins]
#!/usr/bin/env python

from distutils.core import setup
import setuptools

setup(name='<your package name>',
    version='<version>',
    description='<description>',
    author='<your name',
    author_email='<your email>',
    packages=['<package name>'],
    # ... any other args
    entry_points={
        'ikkuna.export.subscriber': [
            'YourSubscriber = module.file:YourSubscriber',
        ]
    })
\end{lstlisting}

\subsection{Documentation}\label{doc}

The entire codebase is liberally documented using the Sphinx documentation
processor\footnote{\url{http://www.sphinx-doc.org/}}. The documentation contains
further documents with a detailed user guide, installation instructions. Sphinx
allows generating documentation in many formats from the same source, most
usefully HTML and PDF. At the time of writing, the HTML documentation and API
reference is hosted at \url{https://peltarion.github.io/ai_ikkuna/}.
