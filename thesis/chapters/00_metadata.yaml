---
title: Training Introspection for Artificial Neural Networks
author: Rasmus Diederichsen
linkcolor: teal
abstract: "Artificial neural networks have become the prevalent model class for many
    machine learning tasks, including image classification, segmentation, video and
    audio analysis, or time series prediction. With ever increasing computational
    resources and advances in programming infrastructure, the size of model we can
    train also increases. Nevertheless, it is not uncommon for training to take days
    or weeks, even on potent hardware. While there are many obvious causes -- e.g.
    inherent difficulty to parallelize training with the most successful algorithms
    -- there may still be inefficiencies in the framework we typically use for
    training neural networks. While the success of deep learning models has been
    rapid, the theoretical justification for most game-changing ideas as well as the
    general principles of deep learning, has not kept pace (ICML reference). This
    means that for many successful techniques, we have no clear understanding why
    they work so well in practice.

    This explanatory gap is also a reason why developing deep learning applications
    is considered more of an art than a science. In contrast to traditional
    programming, which builds on decades of reasearch and development in electrical
    engineering, logic, mathematics and theoretical computer science, there's rarely
    one definitive way to solve a certain problem in deep learning. Additionally,
    the debugging tools available to every programmer on every level of abstraction
    far exceed what we currently have for differentiable programming. Simple
    questions like \"Does my model learn what I want it to learn?\" are not answerable
    at this point.  We can thus identify a need to supply more useful tooling for
    deep learning practitioners.  A standard approch to choosing a parametrization
    remains trial-and-error, or only slighty more sophisticated ways to run and
    test.  The computational cost of training large models prohibits quick
    experimentation and often translates into monetary costs as well. Identifying
    dead ends early or points in training  when to tweak certain parameters could
    thus provide large savings in time and money, besides enabling a more thorough
    understanding of what is going on.

    The road to a deeper understanding does not start with a researcher sitting and
    thinking until eureka happens. More likely, an existing intuition based on
    experience or expertise is validated by experiments and then investigate
    thoroughly in order to justify it mathematically. Cutting out inefficiencies in
    this process also requires adequate tooling that assists as much as possible in
    experimentation.

    This thesis addresses the above in two ways: A software library aiding in deep
    learning debugging and experimentation is designed and implemented. The same
    library is then used to investigate experimentally, whether heretofore unknown
    signals can be extracted from the training process in order to validate
    parameter choices while training is running."
toc: true
---
