---
title: Training Introspection for Artificial Neural Networks
author: Rasmus Diederichsen
# pandoc-crossref vars
listings: true
nameInLink: true
cref: true
figPrefix:
    - "figure"
    - "figures"
eqnPrefix:
    - "equation"
    - "equations"
lstPrefix:
    - "listing"
    - "listings"
secPrefix:
    - "section"
    - "sections"
#--------
abstract: |
    Artificial neural networks have become the prevalent model class for many
    machine learning tasks, including image classification, segmentation, video and
    audio analysis, or time series prediction. With ever increasing computational
    resources and advances in programming infrastructure, the size of model we can
    train also increases. Nevertheless, it is not uncommon for training to take days
    or weeks, even on potent hardware. While there are many obvious causes -- e.g.
    inherent difficulty to parallelize training with the most successful algorithms
    -- there may still be inefficiencies in the framework we typically use for
    training neural networks. While the success of deep learning models has been
    rapid, the theoretical justification for most game-changing ideas as well as the
    general principles of deep learning, has not kept pace (for more
    information, see Sanjeev Arora's talk at ICML 2018 [^youtube]). This means that for
    many successful techniques, we have no clear understanding why
    they work so well in practice.

    [^youtube]: [Toward Theoretical Understanding of Deep Learning](https://www.youtube.com/watch?v=rcR6P5O8CpU)

    This explanatory gap is also a reason why developing deep learning applications
    is considered more of an art than a science. In contrast to traditional
    programming, which builds on decades of reasearch and development in electrical
    engineering, logic, mathematics and theoretical computer science, there's rarely
    one definitive way to solve a certain problem in deep learning. Additionally,
    the debugging tools available to every programmer on every level of abstraction
    far exceed what we currently have for differentiable programming. Simple
    questions like "Does my model learn what I want it to learn?" are not answerable
    at this point.  We can thus identify a need to supply more useful tooling for
    deep learning practitioners.  A standard approch to choosing a parametrization
    remains trial-and-error, or only slighty more sophisticated ways to run and
    test.  The computational cost of training large models prohibits quick
    experimentation and often translates into monetary costs as well. Identifying
    dead ends early or points in training  when to tweak certain parameters could
    thus provide large savings in time and money, besides enabling a more thorough
    understanding of what is going on.

    This thesis addresses the above in two ways: A software library aiding in deep
    learning debugging and experimentation is designed and implemented. The same
    library is then used to investigate experimentally, whether heretofore unknown
    signals can be extracted from the training process in order to validate
    parameter choices while training is running.

zusammenfassung: |
    Künstliche neuronale Netze sind inzwischen die populärste Art von Modell für
    viele Anwendungen im Maschinellen Lernen, z.B. Bildklassifikation,
    Segmentierung oder Video- und Audioanalyse sowie Zeitreihenvorhersage.  Mit
    immer zunehmenden Ressourcen und Fortschritten in verfügbarer Software
    steigt auch die Größe der Trainierbaren Modelle. Dennoch sind
    Trainingszeiten von Tagen und Wochen -- selbst auf potenter Hardware --
    nicht ungewöhnlich.

    Es gibt naheliegende Ursachen -- z.B. die Schwierigkeit, das Training zu
    parallelisieren aufgrund der eingesetzten Optimierungsalgorithmen -- jedoch
    möglicherweise auch weninger offensichtliche Verluste in der Art und Weise,
    wie Modelle normalerweise trainiert werden.

    Während der praktische Erfolg tiefer neuronaler Netze rapide war, konnte die
    theoretische Erschließung nicht Schritt halten, und viele fortschrittliche
    Ideen sind mehr von Intuition und Experimenten gestützt als von rigorosen
    Formalismen.  Für die meisten erfolgreichen Ideen haben wir folglich kein
    klares Verständnis dafür, warum sie in der Praxis gut funktionieren.

    Diese Kluft zwischen Praxis und Theorie ist auch ursächlich dafür, dass
    Deep-Learning-Applikationen mehr als Kunst denn als Wissenschaft gilt.
    Anders als in der traditionellen Softwareentwicklung, die auf Jahrzenten der
    Forschung in Ingenieurswissenschaften, Mathematik und theoretischer
    Informatik basiert, gibt es im maschinellen Lernen oft keinen definitiven Ansatz, um ein
    konkretes Problem zu lösen. Des Weiteren sind die verfügbaren
    Debugging-Wekrzeuge in jeder Schicht der Softwareentwicklung denen des Deep
    Learning bei weitem überlegen. Einfache Fragen wie "Lernt das Modell das, was ich möchte?"
    sind bislang nicht zu beantworten. Wir können hier also eine Notwendigkeit
    für mehr nützliche Tools für Anwender konstatieren.

    Der Standardweg, eine gute Parameterwahl für das Modell zu treffen ist Trial-and-Error
    oder etwas intelligentere Variationen. Der Rechenaufwand für das Training großer Modelle
    verhindert schnelles Experimentieren und schlägt sich häufig auch in finanziellen Kosten nieder.
    Frühzeitig Sackgassen zu identifizieren oder Zeitpunkte, an denen man bestimmte Parameter ändern sollte,
    könnten daher große Ersparnisse bedeuten.

    Diese Arbeit stellt zum Einen eine Softwarebibliothek vor, die im Debugging
    von Deep-Learning-Anwendungen hilft und das Experimentieren erleichtert. Zum
    Anderen wird dieses Werkzeug benutzt, um experimentell festzustellen, ob aus
    dem Trainingsprozess Signale extrahiert werden können, die Aufschluss über
    die Wahl von Parametern geben, während das Training läuft.
toc: true
bibliography: bibliography.bib
csl: apa.csl
---
